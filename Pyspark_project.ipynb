{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "spark=SparkSession.builder.appName(\"pyspark-project\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Q1. Set the schema for all the data sets and load them from different locations using file structured streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining the schema for all the csv files\n",
    "\n",
    "orders_schema = tp.StructType([\n",
    "    tp.StructField(name= \"Order_ID\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"Order_Date\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Order_Priority\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Ord_id\",dataType= tp.StringType()),\n",
    "])\n",
    "market_schema = tp.StructType([\n",
    "    tp.StructField(name= \"ord_id\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Prod_id\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Ship_id\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Cust_id\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Sales\",dataType= tp.DoubleType()),\n",
    "    tp.StructField(name= \"Discount\",dataType= tp.DoubleType()),\n",
    "    tp.StructField(name= \"Order_Quantity\",dataType= tp.IntegerType()),\n",
    "    \n",
    "    tp.StructField(name= \"Profit\",dataType= tp.DoubleType()),\n",
    "    tp.StructField(name= \"Shipping_cost\",dataType= tp.DoubleType()),\n",
    "    tp.StructField(name= \"Product_Base_Margin\",dataType= tp.StringType()),\n",
    "    \n",
    "])\n",
    "shipping_schema = tp.StructType([\n",
    "    tp.StructField(name= \"Order_id\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"Ship_Mode\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Ship_Date\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Ship_id\",dataType= tp.StringType()),\n",
    "    \n",
    "])\n",
    "customer_schema = tp.StructType([\n",
    "    tp.StructField(name= \"Customer_Name\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Province\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Region\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Customer_Segment\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Cust_id\",dataType= tp.StringType()),\n",
    "\n",
    "])\n",
    "\n",
    "product_schema = tp.StructType([\n",
    "    tp.StructField(name= \"Product_Category\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Product_Sub_Category\",dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"Prod_id\",dataType= tp.StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = spark.readStream.schema(orders_schema).option(\"header\", True).csv(\"/user/narendrag85qgre/pyspark/orders\") \n",
    "df2 = df1.writeStream.format(\"memory\").queryName(\"orders_query\").outputMode(\"append\").start() \n",
    "\n",
    "# To convert order to DataFrame\n",
    "order_df = spark.sql(\"SELECT * FROM orders_query\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = spark.readStream.schema(product_schema).option(\"header\", True).csv(\"/user/narendrag85qgre/pyspark/product\") \n",
    "df4 = df3.writeStream.format(\"memory\").queryName(\"product_query\").outputMode(\"append\").start() \n",
    "\n",
    "# To convert product to DataFrame\n",
    "product_df = spark.sql(\"SELECT * FROM product_query\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5 = spark.readStream.schema(customer_schema).option(\"header\", True).csv(\"/user/narendrag85qgre/pyspark/customer\") \n",
    "df6 = df5.writeStream.format(\"memory\").queryName(\"customer_query\").outputMode(\"append\").start() \n",
    "\n",
    "# To convert customer to DataFrame\n",
    "customer_df = spark.sql(\"SELECT * FROM customer_query\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = spark.readStream.schema(market_schema).option(\"header\", True).csv(\"/user/narendrag85qgre/pyspark/market\") \n",
    "df8 = df7.writeStream.format(\"memory\").queryName(\"market_query\").outputMode(\"append\").start() \n",
    "\n",
    "# To convert market to DataFrame\n",
    "market_df = spark.sql(\"SELECT * FROM market_query\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = spark.readStream.schema(shipping_schema).option(\"header\", True).csv(\"/user/narendrag85qgre/pyspark/shipping\") \n",
    "df10= df9.writeStream.format(\"memory\").queryName(\"shipping_query\").outputMode(\"append\").start() \n",
    "\n",
    "# To convert shipping to DataFrame\n",
    "shipping_df = spark.sql(\"SELECT * FROM shipping_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Product_Sub_Category: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      "\n",
      "+----------------+--------------------+-------+\n",
      "|Product_Category|Product_Sub_Category|Prod_id|\n",
      "+----------------+--------------------+-------+\n",
      "| OFFICE SUPPLIES|STORAGE & ORGANIZ...| Prod_1|\n",
      "| OFFICE SUPPLIES|          APPLIANCES| Prod_2|\n",
      "+----------------+--------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None None\n",
      "root\n",
      " |-- Order_ID: integer (nullable = true)\n",
      " |-- Order_Date: string (nullable = true)\n",
      " |-- Order_Priority: string (nullable = true)\n",
      " |-- Ord_id: string (nullable = true)\n",
      "\n",
      "+--------+----------+--------------+------+\n",
      "|Order_ID|Order_Date|Order_Priority|Ord_id|\n",
      "+--------+----------+--------------+------+\n",
      "|       3|13-10-2010|           LOW| Ord_1|\n",
      "|     293|01-10-2012|          HIGH| Ord_2|\n",
      "+--------+----------+--------------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None None\n",
      "root\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer_Segment: string (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      "\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "|     Customer_Name|Province| Region|Customer_Segment|Cust_id|\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "|MUHAMMED MACINTYRE| NUNAVUT|NUNAVUT|  SMALL BUSINESS| Cust_1|\n",
      "|      BARRY FRENCH| NUNAVUT|NUNAVUT|        CONSUMER| Cust_2|\n",
      "+------------------+--------+-------+----------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None None\n",
      "root\n",
      " |-- Order_id: integer (nullable = true)\n",
      " |-- Ship_Mode: string (nullable = true)\n",
      " |-- Ship_Date: string (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      "\n",
      "+--------+--------------+----------+-------+\n",
      "|Order_id|     Ship_Mode| Ship_Date|Ship_id|\n",
      "+--------+--------------+----------+-------+\n",
      "|       3|   REGULAR AIR|20-10-2010|  SHP_1|\n",
      "|     293|DELIVERY TRUCK|02-10-2012|  SHP_2|\n",
      "+--------+--------------+----------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None None\n",
      "root\n",
      " |-- ord_id: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Order_Quantity: integer (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Shipping_cost: double (nullable = true)\n",
      " |-- Product_Base_Margin: string (nullable = true)\n",
      "\n",
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "|  ord_id|Prod_id| Ship_id|  Cust_id| Sales|Discount|Order_Quantity|Profit|Shipping_cost|Product_Base_Margin|\n",
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "|Ord_5446|Prod_16|SHP_7609|Cust_1818|136.81|    0.01|            23|-30.51|          3.6|               0.56|\n",
      "|Ord_5406|Prod_13|SHP_7549|Cust_1818| 42.27|    0.01|            13|  4.56|         0.93|               0.54|\n",
      "+--------+-------+--------+---------+------+--------+--------------+------+-------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "#checking schema and dataframes\n",
    "dataframes={\"product\":product_df,\"order\":order_df,\"customer\":customer_df,\"shipping\":shipping_df,\"market\":market_df}\n",
    "for i in dataframes.keys():\n",
    "    print(dataframes[i].printSchema(),dataframes[i].show(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Join all the Data frames and create a new Data frame called Full_DataFrame in such a way that the new data frame does not contain duplicate columns. (cust_dimen, market_fact, orders_dimen, prod_dimen, shipping_dimen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------\n",
      " Order_id             | 36262                         \n",
      " Ship_id              | SHP_7609                      \n",
      " Ship_Mode            | REGULAR AIR                   \n",
      " Ship_Date            | 28-07-2010                    \n",
      " Cust_id              | Cust_1818                     \n",
      " Customer_Name        | AARON BERGMAN                 \n",
      " Province             | ALBERTA                       \n",
      " Region               | WEST                          \n",
      " Customer_Segment     | CORPORATE                     \n",
      " Prod_id              | Prod_16                       \n",
      " Product_Category     | OFFICE SUPPLIES               \n",
      " Product_Sub_Category | SCISSORS, RULERS AND TRIMMERS \n",
      " Ord_id               | Ord_5446                      \n",
      " Order_Date           | 27-07-2010                    \n",
      " Order_Priority       | NOT SPECIFIED                 \n",
      " Sales                | 136.81                        \n",
      " Discount             | 0.01                          \n",
      " Order_Quantity       | 23                            \n",
      " Profit               | -30.51                        \n",
      " Shipping_cost        | 3.6                           \n",
      " Product_Base_Margin  | 0.56                          \n",
      "-RECORD 1---------------------------------------------\n",
      " Order_id             | 20513                         \n",
      " Ship_id              | SHP_7549                      \n",
      " Ship_Mode            | EXPRESS AIR                   \n",
      " Ship_Date            | 08-07-2009                    \n",
      " Cust_id              | Cust_1818                     \n",
      " Customer_Name        | AARON BERGMAN                 \n",
      " Province             | ALBERTA                       \n",
      " Region               | WEST                          \n",
      " Customer_Segment     | CORPORATE                     \n",
      " Prod_id              | Prod_13                       \n",
      " Product_Category     | OFFICE SUPPLIES               \n",
      " Product_Sub_Category | PENS & ART SUPPLIES           \n",
      " Ord_id               | Ord_5406                      \n",
      " Order_Date           | 07-07-2009                    \n",
      " Order_Priority       | HIGH                          \n",
      " Sales                | 42.27                         \n",
      " Discount             | 0.01                          \n",
      " Order_Quantity       | 13                            \n",
      " Profit               | 4.56                          \n",
      " Shipping_cost        | 0.93                          \n",
      " Product_Base_Margin  | 0.54                          \n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Order_id: integer (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      " |-- Ship_Mode: string (nullable = true)\n",
      " |-- Ship_Date: string (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer_Segment: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Product_Sub_Category: string (nullable = true)\n",
      " |-- Ord_id: string (nullable = true)\n",
      " |-- Order_Date: string (nullable = true)\n",
      " |-- Order_Priority: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Order_Quantity: integer (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Shipping_cost: double (nullable = true)\n",
      " |-- Product_Base_Margin: string (nullable = true)\n",
      "\n",
      "no of columns 21\n"
     ]
    }
   ],
   "source": [
    "# joining market and order\n",
    "join_type=\"inner\"\n",
    "Full_DataFrame=order_df.join(market_df,on=\"ord_id\",how=join_type)\n",
    "# joining product and market df\n",
    "Full_DataFrame=product_df.join(Full_DataFrame,on=\"Prod_id\",how=join_type)\n",
    "#joining customer and market\n",
    "Full_DataFrame=customer_df.join(Full_DataFrame,on=\"Cust_id\",how=join_type)\n",
    "# joining shipping and market \n",
    "Full_DataFrame=shipping_df.join(Full_DataFrame,on=[\"Order_id\",\"Ship_id\"],how=join_type)\n",
    "\n",
    "\n",
    "Full_DataFrame.show(2,False,True)\n",
    "\n",
    "\n",
    "Full_DataFrame.printSchema()\n",
    "\n",
    "\n",
    "print(\"no of columns\",len(Full_DataFrame.columns)) #21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Convert the Order_Date and Ship_Date columns type into Date type. And print the schema and show the top 5 records for Order_Date and Ship_Date columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|order_Date| ship_date|\n",
      "+----------+----------+\n",
      "|2010-07-27|2010-07-28|\n",
      "|2009-07-07|2009-07-08|\n",
      "|2010-07-27|2010-07-27|\n",
      "|2010-11-09|2010-11-11|\n",
      "|2009-07-01|2009-07-08|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Order_id: integer (nullable = true)\n",
      " |-- Ship_id: string (nullable = true)\n",
      " |-- Ship_Mode: string (nullable = true)\n",
      " |-- Ship_Date: date (nullable = true)\n",
      " |-- Cust_id: string (nullable = true)\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Province: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Customer_Segment: string (nullable = true)\n",
      " |-- Prod_id: string (nullable = true)\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Product_Sub_Category: string (nullable = true)\n",
      " |-- Ord_id: string (nullable = true)\n",
      " |-- Order_Date: date (nullable = true)\n",
      " |-- Order_Priority: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Order_Quantity: integer (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- Shipping_cost: double (nullable = true)\n",
      " |-- Product_Base_Margin: string (nullable = true)\n",
      " |-- DaysTakenForDelivery: integer (nullable = true)\n",
      " |-- total_sales: double (nullable = true)\n",
      " |-- total_profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "Full_DataFrame = Full_DataFrame.withColumn(\"Order_Date\", to_date(col(\"Order_Date\"), \"dd-MM-yyyy\"))\n",
    "Full_DataFrame = Full_DataFrame.withColumn(\"Ship_Date\", to_date(col(\"Ship_Date\"), \"dd-MM-yyyy\"))\n",
    "Full_DataFrame.select(\"order_Date\",\"ship_date\").show(5)\n",
    "Full_DataFrame.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Find the top 3 customers who have the maximum number of orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+----------+\n",
      "|  Cust_id|    Customer_Name|num_orders|\n",
      "+---------+-----------------+----------+\n",
      "|Cust_1140|    PATRICK JONES|        17|\n",
      "| Cust_576|MICHAEL DOMINGUEZ|        16|\n",
      "| Cust_999|    SALLY HUGHSBY|        15|\n",
      "+---------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.createOrReplaceTempView(\"fulltable\")\n",
    "spark.sql(\"\"\"SELECT Cust_id,Customer_Name, COUNT(DISTINCT Ord_id) AS num_orders\n",
    "FROM fulltable\n",
    "GROUP BY Cust_id,Customer_name\n",
    "ORDER BY num_orders DESC\n",
    "LIMIT 3\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Create a new column DaysTakenForDelivery that contains the date difference between Order_Date and Ship_Date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------+----------+--------------------+\n",
      "|  ord_id|order_id| ship_date|order_date|DaysTakenForDelivery|\n",
      "+--------+--------+----------+----------+--------------------+\n",
      "|Ord_5446|   36262|2010-07-28|2010-07-27|                   1|\n",
      "|Ord_5406|   20513|2009-07-08|2009-07-07|                   1|\n",
      "|Ord_5446|   36262|2010-07-27|2010-07-27|                   0|\n",
      "|Ord_5456|   39682|2010-11-11|2010-11-09|                   2|\n",
      "|Ord_5485|   54019|2009-07-08|2009-07-01|                   7|\n",
      "|Ord_5446|   36262|2010-07-28|2010-07-27|                   1|\n",
      "|  Ord_31|    4132|2011-05-30|2011-05-28|                   2|\n",
      "|Ord_4725|   46662|2011-12-31|2011-12-29|                   2|\n",
      "|Ord_4725|   46662|2011-12-31|2011-12-29|                   2|\n",
      "|Ord_4725|   46662|2011-12-31|2011-12-29|                   2|\n",
      "+--------+--------+----------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame=Full_DataFrame.withColumn(\"DaysTakenForDelivery\",datediff(col(\"ship_Date\"),col(\"order_Date\")))\n",
    "\n",
    "Full_DataFrame.select(\"ord_id\",'order_id',\"ship_date\",\"order_date\",\"DaysTakenForDelivery\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Find the customer whose order took the maximum time to get delivered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------------------+\n",
      "|Customer_Name|  Ord_id|DaysTakenForDelivery|\n",
      "+-------------+--------+--------------------+\n",
      "|  DEAN PERCER|Ord_4335|                  92|\n",
      "+-------------+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Full_DataFrame.orderBy(\"DaysTakenForDelivery\",ascending=False).select(\"Customer_Name\",\"Ord_id\",\"DaysTakenForDelivery\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Using the windows function, retrieve total sales made by each product from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|prod_id|       total_Sales|\n",
      "+-------+------------------+\n",
      "| Prod_4| 1889313.801999998|\n",
      "| Prod_1|1070182.6000000006|\n",
      "| Prod_7|15006.630000000001|\n",
      "| Prod_8| 795875.9399999998|\n",
      "|Prod_13|167107.21999999997|\n",
      "|Prod_14|1130361.2999999996|\n",
      "|Prod_16| 80996.30999999997|\n",
      "| Prod_2| 736991.5399999997|\n",
      "|Prod_11|1896008.1420000014|\n",
      "|Prod_10| 822652.0400000003|\n",
      "|Prod_17|2168697.1400000006|\n",
      "| Prod_5| 698093.8100000003|\n",
      "|Prod_15|        1761836.55|\n",
      "| Prod_3|1022957.5900000007|\n",
      "|Prod_12| 38981.55000000002|\n",
      "| Prod_6| 446452.8599999995|\n",
      "| Prod_9|174085.80000000008|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "window_specification= Window.partitionBy(\"Prod_id\")\n",
    "Full_DataFrame=Full_DataFrame.withColumn(\"total_sales\",sum(col('Sales')).over(window_specification))\n",
    "Full_DataFrame.select(\"prod_id\",\"total_Sales\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Using the windows function retrieve the total profit made from each product from the data and also do without the windows function using pyspark data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|prod_id|      total_profit|\n",
      "+-------+------------------+\n",
      "| Prod_4| 316951.6200000003|\n",
      "| Prod_1| 6664.149999999999|\n",
      "| Prod_7|-102.6700000000001|\n",
      "| Prod_8| 94287.48000000001|\n",
      "|Prod_13| 7564.780000000003|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Full_DataFrame=Full_DataFrame.withColumn('total_profit',sum(col(\"profit\")).over(window_specification))\n",
    "Full_DataFrame.select(\"prod_id\",\"total_profit\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|prod_id|       total_profit|\n",
      "+-------+-------------------+\n",
      "| Prod_4| 316951.62000000005|\n",
      "| Prod_1| 6664.1500000000015|\n",
      "| Prod_7|-102.66999999999996|\n",
      "| Prod_8|  94287.47999999998|\n",
      "|Prod_13|            7564.78|\n",
      "|Prod_14| 167361.48999999996|\n",
      "|Prod_16|           -7799.25|\n",
      "| Prod_2|           97158.06|\n",
      "|Prod_11| -99062.49999999999|\n",
      "|Prod_10|-33582.130000000005|\n",
      "|Prod_17|          307712.93|\n",
      "| Prod_5|          100427.93|\n",
      "|Prod_15| 149649.72999999998|\n",
      "| Prod_3|          307413.39|\n",
      "|Prod_12| 13677.170000000002|\n",
      "| Prod_6|  45263.19999999999|\n",
      "| Prod_9|  48182.59999999999|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using normal pyspark\n",
    "Full_DataFrame.groupBy(\"prod_id\").agg(sum(col(\"profit\")).alias(\"total_profit\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Count the total number of unique customers in January and how many of them came back every month over the entire year in 2011.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|  cust_id|monthly_parchased|\n",
      "+---------+-----------------+\n",
      "|Cust_1337|                9|\n",
      "| Cust_572|                9|\n",
      "| Cust_478|                8|\n",
      "|Cust_1799|                8|\n",
      "| Cust_501|                8|\n",
      "|Cust_1682|                8|\n",
      "| Cust_525|                8|\n",
      "| Cust_458|                8|\n",
      "| Cust_487|                7|\n",
      "| Cust_595|                7|\n",
      "|  Cust_65|                7|\n",
      "|Cust_1675|                7|\n",
      "|Cust_1742|                7|\n",
      "|Cust_1334|                7|\n",
      "|  Cust_68|                6|\n",
      "| Cust_214|                6|\n",
      "| Cust_138|                6|\n",
      "|Cust_1338|                6|\n",
      "| Cust_939|                6|\n",
      "|Cust_1063|                6|\n",
      "+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "unique customer in jan is 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# filter out 2011 and january month from full dataframe\n",
    "df_jan_2011=Full_DataFrame.filter((year('Order_Date') == 2011) & (month('Order_Date') == 1))\n",
    "\n",
    "# Total number of unique customer in january\n",
    "unique_cust_jan=df_jan_2011.select('Cust_id').distinct().count()\n",
    "\n",
    "\n",
    "\n",
    "every_month_cust=Full_DataFrame.filter((year('Order_Date') == 2011)).groupBy(\"cust_id\")\\\n",
    ".agg(count(month(\"order_date\")).alias(\"monthly_parchased\"))\n",
    "customer_come_backs=every_month_cust.filter\n",
    "every_month_cust.orderBy(\"monthly_parchased\",ascending=False).show()\n",
    "\n",
    "\n",
    "print(\"unique customer in jan is\",unique_cust_jan)\n",
    "\n",
    "#no unique customers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. Calculate the total quantity purchased, discount received by the customer, and calculate the total sales sold and profit earned from each customer. Order the data frame on Total_profit in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------+-------------------+------------------+------------------+\n",
      "|  cust_id|     customer_name|total_quantity|     total_discount|       total_sales|      total_profit|\n",
      "+---------+------------------+--------------+-------------------+------------------+------------------+\n",
      "|Cust_1151|        EMILY PHAN|           129|                0.4|         97011.194|          28663.71|\n",
      "|  Cust_63|     GRANT CARROLL|           242|0.29000000000000004|        54368.9085|20877.440000000002|\n",
      "|Cust_1571|    KAREN CARLISLE|           112|0.22000000000000003|         47445.573|          19439.52|\n",
      "|Cust_1421|   LIZ MACKENDRICK|           434|               0.71|         67285.132|          18960.63|\n",
      "| Cust_937|    JOHN STEVENSON|           130|               0.33| 48660.87300000001|          18849.93|\n",
      "|Cust_1799|      RAYMOND BOOK|           567|               0.97| 70426.59000000001|18760.589999999997|\n",
      "| Cust_934|  LOGAN HAUSHALTER|           316| 0.6700000000000002|45000.488999999994|17044.219999999998|\n",
      "|Cust_1748|      CLYTIE KELTY|           181|               0.25|          46147.22|          16080.57|\n",
      "|Cust_1307|       ANDY REITER|           107|               0.38|          35781.38|          15082.66|\n",
      "|Cust_1310|     NICK CREBASSA|           432| 0.5800000000000001| 45458.40700000001|14712.949999999999|\n",
      "| Cust_997|   ALEJANDRO GROVE|           291|0.42000000000000004|54685.799999999996|14125.069999999998|\n",
      "|Cust_1170| DEBORAH BRUMFIELD|            72|               0.18|        29623.5205|          13041.07|\n",
      "|Cust_1763|       RICK WILSON|           100|               0.18|          26812.47|          12552.75|\n",
      "| Cust_466|   RITSA HIGHTOWER|           390| 0.7900000000000001|54630.104499999994|11960.800000000001|\n",
      "|Cust_1746|         BECKY PAK|           304| 0.8400000000000001|        50378.1595|11765.159999999996|\n",
      "|Cust_1007|        JOHN LUCAS|           410| 0.6399999999999999| 72331.87999999998|          11090.07|\n",
      "| Cust_962|JUSTIN MACKENDRICK|           200|0.30000000000000004|          37675.81|          11033.87|\n",
      "|Cust_1143|      NATHAN MAUTZ|           280|               0.25|          40134.96|10869.859999999999|\n",
      "|Cust_1793|       RUBEN DARTT|           217|               0.38|46399.437999999995|          10647.93|\n",
      "| Cust_995|       HAROLD RYAN|           371|               0.48|35884.060000000005|10571.800000000001|\n",
      "+---------+------------------+--------------+-------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Full_DataFrame.groupBy('cust_id','customer_name')\\\n",
    ".agg(sum(col('order_quantity')).alias('total_quantity'),\\\n",
    "sum(col('discount')).alias('total_discount'),\\\n",
    "sum(col('sales')).alias('total_sales'),\\\n",
    "sum(col('profit')).alias('total_profit'))\\\n",
    ".orderBy('Total_Profit',ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
